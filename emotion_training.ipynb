{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Emotion Detection Model Training\n",
    "## Google Colab Notebook\n",
    "\n",
    "This notebook trains a CNN model for facial emotion recognition using the FER2013 dataset.\n",
    "\n",
    "**Features:**\n",
    "- GPU acceleration\n",
    "- Data augmentation\n",
    "- Advanced callbacks (early stopping, learning rate scheduling)\n",
    "- Real-time training visualization\n",
    "- Model export for download\n",
    "\n",
    "**Detected Emotions:** Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q deeplake tensorflow opencv-python matplotlib\n",
    "\n",
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import deeplake\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_loading"
   },
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# Load FER2013 dataset from DeepLake\n",
    "print(\"Loading datasets...\")\n",
    "train_ds = deeplake.load('hub://activeloop/fer2013-train')\n",
    "val_ds = deeplake.load('hub://activeloop/fer2013-public-test')\n",
    "\n",
    "print(f\"Training samples: {len(train_ds):,}\")\n",
    "print(f\"Validation samples: {len(val_ds):,}\")\n",
    "\n",
    "# Emotion labels\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "print(f\"\\nEmotion classes: {emotion_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_viz"
   },
   "source": [
    "## 3. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize"
   },
   "outputs": [],
   "source": [
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    sample = train_ds[i * 1000]\n",
    "    image = sample.images.data()[\"value\"]\n",
    "    label = sample.labels.data()[\"value\"]\n",
    "    \n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].set_title(f\"{emotion_labels[label]}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_gen"
   },
   "source": [
    "## 4. Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "augmentation"
   },
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    \"\"\"Apply data augmentation to an image.\"\"\"\n",
    "    # Random horizontal flip\n",
    "    if np.random.random() > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Random rotation (-15 to 15 degrees)\n",
    "    if np.random.random() > 0.5:\n",
    "        angle = np.random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    # Random brightness adjustment\n",
    "    if np.random.random() > 0.5:\n",
    "        brightness = np.random.uniform(0.7, 1.3)\n",
    "        image = np.clip(image * brightness, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def deeplake_generator(ds, batch_size, augment=False):\n",
    "    \"\"\"Generate batches of data from DeepLake dataset.\"\"\"\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for sample in ds:\n",
    "            image = sample.images.data()[\"value\"]\n",
    "            label = sample.labels.data()[\"value\"]\n",
    "\n",
    "            # Preprocess image\n",
    "            image = cv2.resize(image, (48, 48))\n",
    "            \n",
    "            # Apply augmentation if enabled\n",
    "            if augment:\n",
    "                image = augment_image(image)\n",
    "            \n",
    "            # Normalize and add channel dimension\n",
    "            image = np.expand_dims(image, axis=-1) / 255.0\n",
    "\n",
    "            # One-hot encode the label\n",
    "            label = tf.keras.utils.to_categorical(label, num_classes=7)\n",
    "            label = np.squeeze(label)\n",
    "\n",
    "            batch_images.append(image)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "            # Yield the batch if it's full\n",
    "            if len(batch_images) == batch_size:\n",
    "                yield np.array(batch_images), np.array(batch_labels)\n",
    "                batch_images, batch_labels = [], []\n",
    "\n",
    "        # Handle the remaining samples in the last batch\n",
    "        if batch_images:\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "print(\"Data generators defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_def"
   },
   "source": [
    "## 5. Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create the emotion detection CNN model with batch normalization.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(48, 48, 1)),\n",
    "        \n",
    "        # First convolutional block\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        # Second convolutional block\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        # Dense layers\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(7, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_config"
   },
   "source": [
    "## 6. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "INITIAL_LR = 0.001\n",
    "\n",
    "# Create data generators\n",
    "train_generator = deeplake_generator(train_ds, BATCH_SIZE, augment=True)\n",
    "validation_generator = deeplake_generator(val_ds, BATCH_SIZE, augment=False)\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = len(train_ds) // BATCH_SIZE\n",
    "validation_steps = len(val_ds) // BATCH_SIZE\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"  Validation steps: {validation_steps}\")\n",
    "print(f\"  Initial learning rate: {INITIAL_LR}\")\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LR),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nModel compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "callbacks"
   },
   "source": [
    "## 7. Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_callbacks"
   },
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "callbacks = [\n",
    "    # Save best model\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_emotion_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Early stopping\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 8. Train Model\n",
    "\n",
    "**Note:** This will take some time. With GPU, expect ~2-3 hours for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training completed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## 9. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_results"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].legend(loc='best')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "axes[1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].legend(loc='best')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nFinal Metrics:\")\n",
    "print(f\"  Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"  Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"  Validation Loss: {history.history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export"
   },
   "source": [
    "## 10. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_model"
   },
   "outputs": [],
   "source": [
    "# Save model weights (compatible with your application)\n",
    "model.save_weights('model.weights.h5')\n",
    "print(\"Model weights saved as 'model.weights.h5'\")\n",
    "\n",
    "# Save full model\n",
    "model.save('emotion_model_full.h5')\n",
    "print(\"Full model saved as 'emotion_model_full.h5'\")\n",
    "\n",
    "print(\"\\nâœ… Training complete! Download the files to use in your application.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 11. Download Files\n",
    "\n",
    "Download the trained model files to your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_files"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download model weights\n",
    "print(\"Downloading model.weights.h5...\")\n",
    "files.download('model.weights.h5')\n",
    "\n",
    "# Download full model (optional)\n",
    "print(\"Downloading emotion_model_full.h5...\")\n",
    "files.download('emotion_model_full.h5')\n",
    "\n",
    "# Download training plot\n",
    "print(\"Downloading training_history.png...\")\n",
    "files.download('training_history.png')\n",
    "\n",
    "print(\"\\nâœ… All files downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage"
   },
   "source": [
    "## Usage Instructions\n",
    "\n",
    "1. Download `model.weights.h5` from the files above\n",
    "2. Place it in your project directory (same folder as `main.py`)\n",
    "3. Run your emotion music player application\n",
    "\n",
    "```bash\n",
    "python main.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Training! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
